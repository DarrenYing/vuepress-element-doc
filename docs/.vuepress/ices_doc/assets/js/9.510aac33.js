(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{583:function(t,e,r){"use strict";r.r(e);var a=r(38),s=Object(a.a)({},(function(){var t=this,e=t.$createElement,r=t._self._c||e;return r("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[r("h1",{attrs:{id:"多机多卡训练配置"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#多机多卡训练配置"}},[t._v("#")]),t._v(" 多机多卡训练配置")]),t._v(" "),r("h2",{attrs:{id:"docker容器配置"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#docker容器配置"}},[t._v("#")]),t._v(" Docker容器配置")]),t._v(" "),r("p",[t._v("多机多卡训练需要在linux系统环境下进行，建议使用docker容器")]),t._v(" "),r("blockquote",[r("p",[t._v("首先需要将宿主机的显卡映射到docker容器中，可以使用"),r("a",{attrs:{href:"https://github.com/NVIDIA/nvidia-docker",target:"_blank",rel:"noopener noreferrer"}},[t._v("Nvidia-Docker"),r("OutboundLink")],1),t._v("实现")])]),t._v(" "),r("blockquote",[r("p",[t._v("推荐使用pytorch官方镜像来创建docker容器，用户需要根据自己的cuda版本来选择相应的镜像，\n假设pytorch版本为1.10，cuda版本为11.3，如果需要nvcc编译，则使用\n"),r("code",[t._v("pytorch/pytorch:1.10.0-cuda11.3-cudnn8-devel")]),t._v("镜像，如果不需要，则使用\n"),r("code",[t._v("pytorch/pytorch:1.10.0-cuda11.3-cudnn8-runtime")]),t._v("镜像即可")])]),t._v(" "),r("blockquote",[r("p",[t._v("在创建容器时，需要传入"),r("code",[t._v("--gpus [gpu_id]")]),t._v("来指定想在容器中使用的GPU，另外，用户还需要根据num_workers的大小，传入\n"),r("code",[t._v("--shm-size [size]")]),t._v("参数来为容器分配合适的shared memory")])]),t._v(" "),r("p",[t._v("例如")]),t._v(" "),r("div",{staticClass:"language-shell extra-class"},[r("pre",{pre:!0,attrs:{class:"language-shell"}},[r("code",[t._v("docker run --gpus all --name "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("xxx"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" --shm-size 8g -v "),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("dir1"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(":"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("dir2"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" -it pytorch/pytorch:1.10.0-cuda11.3-cudnn8-runtime\n")])])]),r("p",[t._v("在容器内部，可以通过"),r("code",[t._v("nvidia-smi")]),t._v("命令来测试Nvidia-Docker是否配置成功，使用"),r("code",[t._v("nvcc -V")]),t._v("测试当前环境是否支持nvcc编译")]),t._v(" "),r("h2",{attrs:{id:"docker容器间通信"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#docker容器间通信"}},[t._v("#")]),t._v(" Docker容器间通信")]),t._v(" "),r("p",[t._v("不同机器间的Docker容器是不能直接通信的，需要配置Docker Swarm，创建容器集群服务，下面将详细介绍。")]),t._v(" "),r("blockquote",[r("p",[t._v("Docker Swarm配置教程，暂略")])]),t._v(" "),r("p",[t._v("配置好Docker Swarm后，需要在创建容器时，传入"),r("code",[t._v("--network [swarm_network_name]")]),t._v("参数，使得多个Docker容器能够实现跨主机通信")]),t._v(" "),r("p",[t._v("使用"),r("code",[t._v("ip a")]),t._v("命令查看Docker容器网卡类型（如eth0等），然后可以通过以下两种方式配置相应的环境变量。")]),t._v(" "),r("blockquote",[r("p",[t._v("直接在bash命令行中执行"),r("code",[t._v("export NCCL_SOCKET_IFNAME=eth0")])])]),t._v(" "),r("blockquote",[r("p",[t._v("执行"),r("code",[t._v("vim ~/.bashrc")]),t._v("（需要先按照vim），在文件尾部追加"),r("code",[t._v("export NCCL_SOCKET_IFNAME=eth0")]),t._v("，保存并退出后，\n执行"),r("code",[t._v("source ~/.bashrc")]),t._v("刷新bash")])]),t._v(" "),r("blockquote",[r("p",[t._v("如果需要在程序执行过程中打印更详细的NCCL信息，可以再配置"),r("code",[t._v("export NCCL_DEBUG=INFO")]),t._v("，配置方法同上。")])]),t._v(" "),r("h2",{attrs:{id:"数据集和项目代码"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#数据集和项目代码"}},[t._v("#")]),t._v(" 数据集和项目代码")]),t._v(" "),r("blockquote",[r("p",[t._v("数据集和项目代码需要先上传到uds中，在创建Docker容器时，挂载数据卷映射，将其映射进Docker容器内即可")])]),t._v(" "),r("h2",{attrs:{id:"多机多卡程序执行"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#多机多卡程序执行"}},[t._v("#")]),t._v(" 多机多卡程序执行")]),t._v(" "),r("blockquote",[r("p",[t._v("假设有两台主机，每台主机有两张GPU，则启动命令如下：")])]),t._v(" "),r("p",[t._v("在master机器上执行")]),t._v(" "),r("div",{staticClass:"language-shell extra-class"},[r("pre",{pre:!0,attrs:{class:"language-shell"}},[r("code",[t._v("python -m torch.distributed.launch --nproc_per_node"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" --nnodes"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" --node_rank"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" --use_env --master_addr"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"your_master_ip"')]),t._v(" --master_port"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("29500")]),t._v("  main.py\n")])])]),r("p",[t._v("在另一台机器上执行")]),t._v(" "),r("div",{staticClass:"language-shell extra-class"},[r("pre",{pre:!0,attrs:{class:"language-shell"}},[r("code",[t._v("python -m torch.distributed.launch --nproc_per_node"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" --nnodes"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),t._v(" --node_rank"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" --use_env --master_addr"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"your_master_ip"')]),t._v(" --master_port"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token number"}},[t._v("29500")]),t._v("  main.py\n")])])])])}),[],!1,null,null,null);e.default=s.exports}}]);